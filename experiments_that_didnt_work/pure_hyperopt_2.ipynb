{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import tpe\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pdf['clean_text'], pdf['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 3))\n",
    "X_enc = vec.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_enc, y, test_size=.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ptyshevskyi/envs/loc_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8196969696969697"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "accuracy_score(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=3.801113913337704e-05, average=False,\n",
      "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
      "              eta0=0.01297891019764783, fit_intercept=True,\n",
      "              l1_ratio=0.6287951512009251, learning_rate='constant',\n",
      "              loss='squared_hinge', max_iter=30148914.0, n_iter_no_change=5,\n",
      "              n_jobs=1, penalty='l1', power_t=0.10140007388288363,\n",
      "              random_state=2, shuffle=True, tol=0.00448603330673893,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.6842105263157895\n",
      "OK trial with loss 0.3\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.58s/it, best loss: 0.3157894736842105]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=2.9479784086768314e-06, average=False,\n",
      "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
      "              eta0=3.476262253283762e-05, fit_intercept=True,\n",
      "              l1_ratio=0.2692204953765216, learning_rate='invscaling',\n",
      "              loss='modified_huber', max_iter=214415888.0, n_iter_no_change=5,\n",
      "              n_jobs=1, penalty='l1', power_t=0.7866257089547786,\n",
      "              random_state=0, shuffle=True, tol=1.930436965150289e-05,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.8269794721407624\n",
      "OK trial with loss 0.2\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.08s/it, best loss: 0.1730205278592376]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=1.8970958978217467e-06, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.00454622458243822,\n",
      "              fit_intercept=True, l1_ratio=0.46584526414363636,\n",
      "              learning_rate='optimal', loss='epsilon_insensitive',\n",
      "              max_iter=51518189.0, n_iter_no_change=5, n_jobs=1, penalty='l1',\n",
      "              power_t=0.4859524362849118, random_state=2, shuffle=True,\n",
      "              tol=0.0002851259820854015, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.009950248756218907\n",
      "OK trial with loss 1.0\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it, best loss: 0.1730205278592376]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.035117457122916876, average=False,\n",
      "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
      "              eta0=1.3615551114464812e-05, fit_intercept=True,\n",
      "              l1_ratio=0.5991573854087219, learning_rate='constant',\n",
      "              loss='squared_hinge', max_iter=429082879.0, n_iter_no_change=5,\n",
      "              n_jobs=1, penalty='elasticnet', power_t=0.8080536202624006,\n",
      "              random_state=0, shuffle=True, tol=1.2361030795593664e-05,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.664440734557596\n",
      "OK trial with loss 0.3\n",
      "100%|██████████| 1/1 [00:11<00:00, 11.77s/it, best loss: 0.1730205278592376]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.07244749675638744, average=False, class_weight='balanced',\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.014746536920429577,\n",
      "              fit_intercept=True, l1_ratio=0.317078716880435,\n",
      "              learning_rate='optimal', loss='log', max_iter=36691106.0,\n",
      "              n_iter_no_change=5, n_jobs=1, penalty='l2',\n",
      "              power_t=0.8615311393879181, random_state=4, shuffle=True,\n",
      "              tol=1.1105565248338581e-05, validation_fraction=0.1,\n",
      "              verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.5321100917431192\n",
      "OK trial with loss 0.5\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it, best loss: 0.1730205278592376]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.008384506618921506, average=False,\n",
      "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
      "              eta0=1.8430784352690082e-05, fit_intercept=True,\n",
      "              l1_ratio=0.03266301969084151, learning_rate='invscaling',\n",
      "              loss='hinge', max_iter=14440841.0, n_iter_no_change=5, n_jobs=1,\n",
      "              penalty='l1', power_t=0.38342158063095233, random_state=4,\n",
      "              shuffle=True, tol=0.009464913712541989, validation_fraction=0.1,\n",
      "              verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.8732394366197184\n",
      "OK trial with loss 0.1\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=1.7873753714147182e-05, average=False,\n",
      "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
      "              eta0=0.0005254495942666862, fit_intercept=True,\n",
      "              l1_ratio=0.14894846925425265, learning_rate='constant',\n",
      "              loss='modified_huber', max_iter=44072507.0, n_iter_no_change=5,\n",
      "              n_jobs=1, penalty='l2', power_t=0.7638698566515887,\n",
      "              random_state=2, shuffle=True, tol=1.1372231910762392e-05,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.36400817995910023\n",
      "OK trial with loss 0.6\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.29s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.0012106623119062941, average=False,\n",
      "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
      "              eta0=0.003663213487148157, fit_intercept=True,\n",
      "              l1_ratio=0.4051749900272448, learning_rate='optimal',\n",
      "              loss='modified_huber', max_iter=100638743.0, n_iter_no_change=5,\n",
      "              n_jobs=1, penalty='elasticnet', power_t=0.7849954149145356,\n",
      "              random_state=4, shuffle=True, tol=4.983901406779075e-05,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.5890652557319224\n",
      "OK trial with loss 0.4\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.03s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.00998530974629806, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.00018681625582308098,\n",
      "              fit_intercept=True, l1_ratio=0.7080594610982648,\n",
      "              learning_rate='constant', loss='log', max_iter=411480614.0,\n",
      "              n_iter_no_change=5, n_jobs=1, penalty='l2',\n",
      "              power_t=0.05313457180603964, random_state=4, shuffle=True,\n",
      "              tol=0.00017434525024245928, validation_fraction=0.1,\n",
      "              verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.2758620689655173\n",
      "OK trial with loss 0.7\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.73s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=1.698215200818242e-05, average=False,\n",
      "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
      "              eta0=0.0020769052908528297, fit_intercept=True,\n",
      "              l1_ratio=0.15488690306800879, learning_rate='constant',\n",
      "              loss='hinge', max_iter=14982630.0, n_iter_no_change=5, n_jobs=1,\n",
      "              penalty='elasticnet', power_t=0.9600897827860518, random_state=0,\n",
      "              shuffle=True, tol=1.7269830960090975e-05, validation_fraction=0.1,\n",
      "              verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.5374771480804388\n",
      "OK trial with loss 0.5\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.0007673662035595492, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0007613969509887961,\n",
      "              fit_intercept=True, l1_ratio=0.9272356437058051,\n",
      "              learning_rate='constant', loss='hinge', max_iter=23432542.0,\n",
      "              n_iter_no_change=5, n_jobs=1, penalty='l1',\n",
      "              power_t=0.7353882071978798, random_state=3, shuffle=True,\n",
      "              tol=0.0013271440063128265, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.5611510791366906\n",
      "OK trial with loss 0.4\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.20s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=5.320686164550699e-05, average=False,\n",
      "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
      "              eta0=0.004246912127848535, fit_intercept=True,\n",
      "              l1_ratio=0.4825474782400341, learning_rate='optimal',\n",
      "              loss='perceptron', max_iter=14725497.0, n_iter_no_change=5,\n",
      "              n_jobs=1, penalty='l1', power_t=0.5346786494363568,\n",
      "              random_state=0, shuffle=True, tol=0.0013520856365211685,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.7240829346092504\n",
      "OK trial with loss 0.3\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.000803906030791948, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.000676528631147356,\n",
      "              fit_intercept=True, l1_ratio=0.7528399132320247,\n",
      "              learning_rate='constant', loss='hinge', max_iter=479669492.0,\n",
      "              n_iter_no_change=5, n_jobs=1, penalty='l2',\n",
      "              power_t=0.5039811807802915, random_state=2, shuffle=True,\n",
      "              tol=0.00032214589785336346, validation_fraction=0.1,\n",
      "              verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.34710743801652894\n",
      "OK trial with loss 0.7\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.009325197678012046, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0003706616057631633,\n",
      "              fit_intercept=True, l1_ratio=0.890517150893919,\n",
      "              learning_rate='constant', loss='modified_huber',\n",
      "              max_iter=35077202.0, n_iter_no_change=5, n_jobs=1, penalty='l1',\n",
      "              power_t=0.9480563252334171, random_state=0, shuffle=True,\n",
      "              tol=5.21943684538395e-05, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.47328244274809156\n",
      "OK trial with loss 0.5\n",
      "100%|██████████| 1/1 [00:06<00:00,  7.00s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.04808710620549519, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01633246795368155,\n",
      "              fit_intercept=True, l1_ratio=0.25047940305530303,\n",
      "              learning_rate='optimal', loss='perceptron', max_iter=172889804.0,\n",
      "              n_iter_no_change=5, n_jobs=1, penalty='l2',\n",
      "              power_t=0.4484830354295354, random_state=4, shuffle=True,\n",
      "              tol=0.0001664244806626925, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.33333333333333337\n",
      "OK trial with loss 0.7\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=1.5319059969238006e-06, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.00025530436277387277,\n",
      "              fit_intercept=True, l1_ratio=0.4463092938749602,\n",
      "              learning_rate='optimal', loss='hinge', max_iter=33664899.0,\n",
      "              n_iter_no_change=5, n_jobs=1, penalty='l1',\n",
      "              power_t=0.732883748782563, random_state=1, shuffle=True,\n",
      "              tol=0.0018774386285221665, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.2222222222222222\n",
      "OK trial with loss 0.8\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=4.6163785280276865e-06, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0003013638220836094,\n",
      "              fit_intercept=True, l1_ratio=0.6653605238711289,\n",
      "              learning_rate='optimal', loss='modified_huber',\n",
      "              max_iter=255142840.0, n_iter_no_change=5, n_jobs=1, penalty='l2',\n",
      "              power_t=0.4877391823976407, random_state=1, shuffle=True,\n",
      "              tol=0.0001443203015470023, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.2608695652173913\n",
      "OK trial with loss 0.7\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=7.058119734560925e-05, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.006990522350485626,\n",
      "              fit_intercept=True, l1_ratio=0.02966803703100873,\n",
      "              learning_rate='invscaling', loss='log', max_iter=332740653.0,\n",
      "              n_iter_no_change=5, n_jobs=1, penalty='elasticnet',\n",
      "              power_t=0.18290991417140956, random_state=3, shuffle=True,\n",
      "              tol=1.7551967972112877e-05, validation_fraction=0.1,\n",
      "              verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.3572895277207392\n",
      "OK trial with loss 0.6\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.61s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.08511153534211892, average=False, class_weight='balanced',\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.014278868677228508,\n",
      "              fit_intercept=True, l1_ratio=0.04165177973597223,\n",
      "              learning_rate='invscaling', loss='hinge', max_iter=864105464.0,\n",
      "              n_iter_no_change=5, n_jobs=1, penalty='l1',\n",
      "              power_t=0.7058973742908824, random_state=4, shuffle=True,\n",
      "              tol=6.630356766864414e-05, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.8700564971751412\n",
      "OK trial with loss 0.1\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.012533156201095715, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.00020259341448015583,\n",
      "              fit_intercept=True, l1_ratio=0.48516786929118083,\n",
      "              learning_rate='optimal', loss='hinge', max_iter=67125086.0,\n",
      "              n_iter_no_change=5, n_jobs=1, penalty='l1',\n",
      "              power_t=0.030091957453287632, random_state=3, shuffle=True,\n",
      "              tol=0.003381542750443246, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.32985386221294366\n",
      "OK trial with loss 0.7\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.96s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.0032534297084294292, average=False,\n",
      "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
      "              eta0=0.05685561960376329, fit_intercept=True,\n",
      "              l1_ratio=0.019493265653586868, learning_rate='invscaling',\n",
      "              loss='squared_loss', max_iter=779568824.0, n_iter_no_change=5,\n",
      "              n_jobs=1, penalty='l1', power_t=0.32101574193375454,\n",
      "              random_state=4, shuffle=True, tol=5.5896926602016735e-05,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.6277873070325901\n",
      "OK trial with loss 0.4\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.09827266881405071, average=False, class_weight='balanced',\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.06824750558905647,\n",
      "              fit_intercept=True, l1_ratio=0.09711222461352205,\n",
      "              learning_rate='invscaling', loss='huber', max_iter=10118304.0,\n",
      "              n_iter_no_change=5, n_jobs=1, penalty='l1',\n",
      "              power_t=0.6270152870236038, random_state=4, shuffle=True,\n",
      "              tol=0.009283856556706369, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.0\n",
      "OK trial with loss 1.0\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.000207472312321752, average=False,\n",
      "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
      "              eta0=6.0500713579472604e-05, fit_intercept=True,\n",
      "              l1_ratio=0.01519279596050304, learning_rate='invscaling',\n",
      "              loss='hinge', max_iter=900599415.0, n_iter_no_change=5, n_jobs=1,\n",
      "              penalty='l1', power_t=0.30957937519593276, random_state=4,\n",
      "              shuffle=True, tol=0.0005440810508658727, validation_fraction=0.1,\n",
      "              verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "Scoring on X/EX validation of shape (400, 1236908)\n",
      "this loss called with f1=0.5157699443413729\n",
      "OK trial with loss 0.5\n",
      "100%|██████████| 1/1 [00:57<00:00, 57.34s/it, best loss: 0.12676056338028163]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Training learner SGDClassifier(alpha=0.003058776343049629, average=False,\n",
      "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
      "              eta0=0.0370114472207668, fit_intercept=True,\n",
      "              l1_ratio=0.17862548801442826, learning_rate='invscaling',\n",
      "              loss='hinge', max_iter=120838651.0, n_iter_no_change=5, n_jobs=1,\n",
      "              penalty='l1', power_t=0.6171222061954956, random_state=4,\n",
      "              shuffle=True, tol=7.635503828580828e-05, validation_fraction=0.1,\n",
      "              verbose=False, warm_start=False) on X/EX of dimension (1600, 1236908)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]\n",
      "Training learner SGDClassifier(alpha=0.008384506618921506, average=False,\n",
      "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
      "              eta0=1.8430784352690082e-05, fit_intercept=True,\n",
      "              l1_ratio=0.03266301969084151, learning_rate='invscaling',\n",
      "              loss='hinge', max_iter=14440841.0, n_iter_no_change=5, n_jobs=1,\n",
      "              penalty='l1', power_t=0.38342158063095233, random_state=4,\n",
      "              shuffle=True, tol=0.009464913712541989, validation_fraction=0.1,\n",
      "              verbose=False, warm_start=False) on X/EX of dimension (2000, 1236908)\n",
      "0.5355\n",
      "{'learner': SGDClassifier(alpha=0.008384506618921506, average=False,\n",
      "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
      "              eta0=1.8430784352690082e-05, fit_intercept=True,\n",
      "              l1_ratio=0.03266301969084151, learning_rate='invscaling',\n",
      "              loss='hinge', max_iter=14440841.0, n_iter_no_change=5, n_jobs=1,\n",
      "              penalty='l1', power_t=0.38342158063095233, random_state=4,\n",
      "              shuffle=True, tol=0.009464913712541989, validation_fraction=0.1,\n",
      "              verbose=False, warm_start=False), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-126:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "\n",
      "  File \"/home/ptyshevskyi/Desktop/UCU/hyperopt-sklearn/hpsklearn/estimator.py\", line 326, in _cost_fn\n",
      "    learner.fit(XEXfit, yfit)\n",
      "\n",
      "  File \"/home/ptyshevskyi/envs/loc_env/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\", line 713, in fit\n",
      "    sample_weight=sample_weight)\n",
      "\n",
      "  File \"/home/ptyshevskyi/envs/loc_env/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\", line 554, in _fit\n",
      "    classes, sample_weight, coef_init, intercept_init)\n",
      "\n",
      "  File \"/home/ptyshevskyi/envs/loc_env/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\", line 514, in _partial_fit\n",
      "    max_iter=max_iter)\n",
      "\n",
      "  File \"/home/ptyshevskyi/envs/loc_env/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\", line 572, in _fit_binary\n",
      "    random_state=self.random_state)\n",
      "\n",
      "  File \"/home/ptyshevskyi/envs/loc_env/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\", line 413, in fit_binary\n",
      "    est.power_t, est.t_, intercept_decay)\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_loss(y_target, y_pred):\n",
    "    f1 = f1_score(y_target, y_pred)\n",
    "    print(f\"this loss called with f1={f1}\")\n",
    "    return 1.0 - f1\n",
    "\n",
    "\n",
    "from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing, any_sparse_classifier, sgd\n",
    "\n",
    "np.random.seed(13)\n",
    "\n",
    "estim = HyperoptEstimator(classifier=sgd('yes'),\n",
    "                          preprocessing=[],\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120,\n",
    "                         loss_fn=f1_loss, verbose=False)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim.fit(X_enc, y, random_state=42, cv_shuffle=False, n_folds=None, )\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim.score(X_enc, y))\n",
    "# 1.0\n",
    "\n",
    "print( estim.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5439999999999999"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = estim.best_model()['learner']\n",
    "cross_val_score(model, X_enc, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0026461806301647244, average=False,\n",
       "              class_weight='balanced', early_stopping=False, epsilon=0.1,\n",
       "              eta0=3.3361348224900434e-05, fit_intercept=True,\n",
       "              l1_ratio=0.03460388488308809, learning_rate='constant',\n",
       "              loss='huber', max_iter=15606531.0, n_iter_no_change=5, n_jobs=1,\n",
       "              penalty='elasticnet', power_t=0.017345142216377618,\n",
       "              random_state=2, shuffle=True, tol=0.0002393463072572627,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8195051338763913"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SGDClassifier(random_state=42), X_enc, y).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
